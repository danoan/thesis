\chapter{Digital Flow Revisited}
\label{chapter:digital-flow-revisited}

In this chapter we give a formal argument for the DCE algorithm presented in chapter \ref{chapter:digital-curve-evolution} along with a different interpretation for it and an easy-to-implement version of the DCE algorithm.

\section{Estimating curvature with outer balls}

Let $\mathcal{C}$ a oriented curve in the plane. We center disks $B_i$ and $B_o$ of radius $R+R/2$ with centers aligned with the normal direction of the curve at some point $p \in \mathcal{C}$. Moreover, the distance from disks center to $p$ equals to $R$.

\begin{figure}
\center
\includegraphics[scale=0.35]{figures/appendix-max-energy/r-separated-disks.png}
\caption{disks of radius $R+1$ distant $R$ units from $p\in \mathcal{C}$ in the normal direction.}
\label{fig:r-separated-disks}
\end{figure}

Let $\theta_o (\theta_i)$ to denote the intersection of $B_o(B_i)$ with the inner(outer) region of the curve. We define the function $g:\mathcal{R} \times \mathcal{C}\rightarrow \mathbb{R}$ as

\begin{align*}
	g_{R}(p) &= \Big( \Theta_o(p) - \Theta_i(p) \;\Big)^2.
\end{align*}

\begin{claim}{R-separated disks curvature}\label{claim:r-separated-disks}
 Let $\mathcal{C} \in \mathbb{R}^2$ be a curve such that for a point $p \in \mathcal{C}$ its curvature equals to $\kappa$. For sufficiently small values of $R$, we can approximate $g$ by


\begin{align*}
g_R(p) \approx & \frac{125}{144}R^6k^2.
\end{align*} 
\end{claim}


\begin{proof} For every point $p$ in $C$, consider its Frenet frame formed by the tangent vector at $p$, $T(p)$ and the normal vector at $p$, $N(p)$. We assume the origin of the frame is at point $p$. Let $x$ be a variable in the axis defined by $T(p)$. Expanding $C(x)$ around the origin we obtain

\begin{align*}
	C(x) &= C(0) + \frac{dC}{dx}x + \frac{1}{2}\frac{d^2C}{dx^2}x^2 + O(x^3) \\
	&= \frac{\kappa}{2}x^2 + O(x^3).
\end{align*}

In other words, the second order approximation for the curve $C$ in the Frenet frame is the parabola $f(x) =  \kappa/2x^2$ passing at the origin. We are going to use this parabola to estimate $\Theta_o$ and $\Theta_i$.

We proceed by computing the intersection area $\theta_o$.


\begin{figure}[h!]\label{fig:parabola-approx-ex}
\center
	\subfloat[\label{}]{%
\includegraphics[scale=0.35]{figures/appendix-max-energy/parabola-approx-1.png}
	}\hspace{20pt}%
	\subfloat[\label{}]{%
\includegraphics[scale=0.35]{figures/appendix-max-energy/parabola-approx-2.png}
	}
\caption{The yellow area corresponds to $\theta_o$ and it equals the area under the parabola from $x=0$ until $x=x_o$ minus the orange area $h(x)$.}
\end{figure}

\begin{align*}
	h(x) &= R+\epsilon - \sqrt{ (R+\epsilon)^2 - x^2}\\
	\theta_o &= 2\int_0^{x_o}{f(x) + \epsilon - h(x)}\\
\end{align*}

To compute the intersection point $x_o$ of the parabola with the disc, we use again pythagoras' theorem.

\begin{align*}
	(R+\epsilon)^2 &= (R-\frac{\kappa}{2}x_o^2)^2 + x_o^2\\
	0 &= \frac{\kappa^2}{4}x_o^4 + (1-R\kappa)x_o^2 + R^2 - (R+\epsilon)^2
\end{align*}

By setting $z_o=x_o^2$

\begin{align*}
\Delta_o &= (1-R\kappa)^2 + \kappa^2(2R\epsilon + \epsilon^2)\\
z_o &= \frac{2}{\kappa^2}(R\kappa-1 + \sqrt{\Delta_o})\\
x_o &= \frac{\sqrt{2}}{\kappa}\sqrt{R\kappa-1+\sqrt{\Delta_o}}
\end{align*}

We proceed similarly for the inner disk.


\begin{figure}[h!]\label{fig:parabola-approx-in}
\center
	\subfloat[\label{}]{%
\includegraphics[scale=0.35]{figures/appendix-max-energy/parabola-approx-3.png}
	}\hspace{15pt}%
	\subfloat[\label{}]{%
\includegraphics[scale=0.35]{figures/appendix-max-energy/parabola-approx-4.png}
	}
\caption{The yellow area corresponds to $\theta_i$ and it equals the area between the parabola and the disc from $x=0$ until $x=x_i$.}
\end{figure}

\begin{align*}
	\theta_i &= 2\int_{0}^{x_i}{\epsilon - f(x) - h(x)}	\end{align*}

The intersection point $x_i$ between the parabola and the inner disk is given by
	
\begin{align*}
	(R+\epsilon)^2 &= (R+\frac{\kappa}{2}x_o^2)^2 + x_i^2\\
	0 &= \frac{\kappa^2}{4}x_i^4 + (1+R\kappa)x_i^2 + R^2 - (R+\epsilon)^2	\\
\Delta_i &= (1+R\kappa)^2 + \kappa^2(2R\epsilon + \epsilon^2)\\
x_i &= \frac{\sqrt{2}}{\kappa}\sqrt{-R\kappa-1+\sqrt{\Delta_i}}.
\end{align*}

The claimed approximation is obtained by expanding $g_R$ with its  6th order Taylor series around $\kappa=0,R=0$.
\end{proof}

Thegore, the squared curvature can be estimated as

\begin{align*}
	\kappa ^2 = \frac{144}{125R^6}g_R(p).
\end{align*}

\section{DCE energy and curvature estimation}

In the previous section we saw how to estimate curvature using the outer balls. In this section we recover the DCE energy using this estimation. Let $R=r+r/2$ for some $r>0$.

\begin{align*}
	g_{R}(p) &= ( \Theta_i - \Theta_o )^2 \\
		   &= \big(\; ( \pi R^2 - F_i - \sum_{X_i}{x} ) - (F_o + \sum_{X_o}{x}) \;\big)^2 \\
		   &= ( \frac{\pi R^2}{2} - F_i - \sum_{X_i}{x} + \frac{\pi R^2}{2} - F_o - \sum_{X_o}{x} )^2.
\end{align*}

Recall that a single term of the DCE energy is written as


\begin{align*}
  T_{R,m}(p) &=  \sum_{p \in R_m(S)}{ c_1\Big( c_2 - |F_{R}(p)| - \sum_{x_j \in X_R(p)} {x_j} \Big)^2 } \\
  	  &= c_1\Big( \frac{\pi R^2}{2} - |F_{R}(p_i)| - \sum_{x_j \in X_{R}(p_{i})} {x_j} \Big)^2 + c_1\Big( \frac{\pi R^2}{2} - |F_{R}(p_o)| - \sum_{x_j \in X_{R}(p_{o})} {x_j} \Big)^2
\end{align*}

Under some conditions, the functions $T_{R,m}$ and $g_R$ have the same minimizer. 

\begin{lemma}
	Let $A_i,A_o$ such that $A_o \leq -A_i$. Define the function $F:\mathbb{R^+}\cup\{0\}\rightarrow \mathbb{R}$ as
	\begin{align*}
		F(y) = (A_i-y)^2 + (A_o - y)^2.
	\end{align*}
	Then 
	
	\begin{align*}
		0=\argmin F.
	\end{align*}
	
\begin{proof}
	\begin{align*}
		\frac{\partial  f}{dy} &= 0 \\
		-2(A_i+A_o-2y) &= 0 \\
		A_i - A_i - 2y \geq A_i + A_o - 2y &= 0\\
		-2y \geq 0.
	\end{align*}
	
	Therefore, $y=0$.
\end{proof}
\end{lemma}


\begin{claim}{Basic solution}
	For sufficiently large values of $m$, there exists a solution $S$ such that
\begin{align*}
	\forall p \quad S \in \argmin T_{R,m}(p) \text{ and } S \in \argmin g_R(p).
\end{align*}

\end{claim}

\begin{proof}
	Let $A_i=\pi R^2/2 - F_i$ and $A_o=\pi R^2/2 -F_o$. We rewrite $E_m$ and $g_R$ as
	\begin{align*}
		E_m &= (A_i - \sum_{X_i}{x} )^2 + (A_o - \sum_{X_o}{x})^2\\
		g_R(p) &= (A_i - \sum_{X_i}{x} + A_o - \sum_{X_o}{x})^2,
	\end{align*}
	
	Assume that $m$ is larger enough such that we have $A_i<0$ and $A_o>0$. We have one of the following cases.\\
	
	\textbf{Case i:} $X_o \subset X_i$ (convexity).
	
	\begin{align*}
		E_m &= (A_i - \sum_{X_i^*}{x} - \sum_{X_o}{x} )^2 + (A_o - \sum_{X_o}{x})^2\\
		g_R(p) &= (A_i - \sum_{X_i^*}{x} - \sum_{X_o}{x} + A_o - \sum_{X_o}{x})^2,
	\end{align*}	
	
	where $X_i^*=X_i \setminus X_o$. Assume solution $S=(X_i^*=0,X_o=1)$. Therefore,
	\begin{align*}
		\frac{dE_m}{dx}(S) &= 0, \; \forall x \\
		-2(A_i - |X_o|) - 2(A_o - |X_o|) &= 0 \\
		|X_o| &= \frac{A_i+A_o}{2}
	\end{align*}
	
	On the other hand, if $S$ is the minimum solution of $g_R$ then
	
	\begin{align*}
		A_o &\geq 2|X_o| = A_i+A_o.
	\end{align*}
	
	The last expression holds, since we assume $A_i<0$.
	
	The second case, $X_i \subset X_o$ (concavity), follows similarly, but the common solution is $S=(X_i=1,X_o^*=0)$.
\end{proof}

The advantage of the DCE energy is that inner and outer terms are computed separately, i.e., there is no need to map the pair of balls. That property makes the algorithm to be much faster and easy to construct.

\section{A single step version of DCE algorithm}
In the DCE algorithm we invert the solution after minimization. The inversion of optimal solution $f(X)$ equals the solution of $f(1-X)$.

\begin{align*}
	\overline{\argmin E_m(X)} = \argmin E_m(1-X).
\end{align*}

Rewriting a simple term $T_m(X)$ as $T_m(1-X)$ we obtain

\begin{align}
	T_m(1-X) &= (A_i - \sum_{X_i}{(1-x)})^2 + (A_o - \sum_{X_o}{(1-x)})^2
	\label{eq:inverted-term}
\end{align}

Consider the first term in $T_m(1-X)$. Expanding it, we have

\begin{align}
	(A_i - \sum_{X_i}{(1-x)})^2 &= (A_i - |X|)^2 + 2(A_i-|X|)\sum{x} + ( \sum{x} )^2 \nonumber  \\
	&= A_i^2 -2A_i|X| + |X|^2 + 2(A_i - |X|)\sum{x} + (\sum{x})^2 \nonumber  \\
	&= A_i^2 + 2A_i\sum{x} + (\sum{x})^2 - 2A_i|X| + |X|^2 - 2|X|\sum{x} \nonumber  \\
	&= 2A_i^2 - (A_i - \sum{x})^2 + (|X| - \sum{x})^2 + (\sum{x})^2 \nonumber \\
	&= 2A_i^2 - (A_i - \sum{x})^2 + (\sum{(1-x)})^2 + (\sum{x})^2 \nonumber  \\
	&= 2A_i^2 - (A_i - \sum{x})^2 + P_1(x).
	\label{eq:first-sum-inverted-term}
\end{align}

where  $P_a=\Big( \sum{a(1-x)} \Big)^2 + \Big(\sum{x}\Big)^2$. Replacing \eqref{eq:first-sum-inverted-term} in \eqref{eq:inverted-term}.

\begin{align}
	T_m(1-X) = -(A_i - \sum_{x})^2 + (A_o - \sum{(1-x)})^2 + P_a(x).
\end{align}

The term $P_a$ is a kind of local penalization. Among those to be labeled one, $P_a$ forces the labeling of only half of them when $a=1$. Indeed,

\begin{align*}
	\min P_a(|X|) &= \frac{a^2|X|}{a^2+1}.
\end{align*}





\section{Potential elastica}

As observed in the previous chapter, a global optimization model is unlikely to be useful in practice. In this section, we are going to explore the definition of the II estimator to derive a process that evolves the shape $S$ based on measurements of its current boundary $\partial S$. We start by defining a naive energy that illustrates some of the issues with this approach and how we can overcome them.

As usual, let $S \in \Omega \in \mathbb{Z}^2$ be a digital shape. We assume an ordering in $\Omega$, i.e., there exists a bijective function $\omega : \Omega \rightarrow \{1 \cdots |\Omega| \}$. Moreover, we associate to any subset $P \subset \Omega$ the set of binary variables $X(P)$ defined as

\begin{align*}
	X(P) := \left\{ x_{\omega(p)} \in \{0,1\} \; | \; p \in P \right\}.
\end{align*}

\begin{definition}{Inner pixel boundary}
Given a digital shape $S \in \Omega \in \mathbb{Z}^2$, we define its inner pixel boundary set $I(S)$ as
\begin{align*}
	I(S) := \left\{ \: p \; | \; p \in S, |\mathcal{N}_4(x) \cap S|<4 \: \right\},
\end{align*}
where $\mathcal{N}_4(p)$ denotes the $4$-adjacent neighbor set of $p$ (without $p$).
\end{definition}


We recall the II estimator definition

\begin{align*}
	\hat{k}(p) = \frac{3}{r^3}\left( \frac{\pi r^2}{2} - |B_r(p) \cap S| \right).
\end{align*}

Consider the following optimization problem and its result for the square shape with parameters $h=0.5,r=10$ in figure \ref{}.

\begin{align}
	\min_{X(I(S)} \sum_{p \in I(S)}{ \Big( \; \frac{\pi r^2}{2} - | (B_r(p) \cap S) \setminus I(S) | - \sum_{ \substack{x_j \in \\ X( I(S) \cap B_r(p))}}{x_j} \; \Big)^2}.
	\label{eq:naive-opt-problem}
\end{align}

\begin{figure}
\center
\subfloat[\label{fig:naive-opt-before}]{
\includegraphics[scale=0.18]{figures/chapter6/contour-information/before-opt.pdf}}
\subfloat[\label{fig:naive-opt-after}]{
\includegraphics[scale=0.18]{figures/chapter6/contour-information/after-opt.pdf}}
\caption{Solution of model \eqref{eq:naive-opt-problem} for the square shape $(h=0.5,r=10)$. In (a) we have the square shape before minimization. Optimization variables are colored yellow. In (b), the resulting shape of the optimization problem. }
\label{fig:naive-opt-problem}
\end{figure}

The solution in figure \ref{fig:naive-opt-after} should not cause any surprise. The energy \eqref{eq:naive-opt-problem} is optimized over a fixed contour, i.e., independently of pixels being labeled zero or one the estimation ball is evaluated at the same initial contour. In section \ref{sec:global-optimization-model} we've defined an optimization energy in which contour information is taken into account, but we end up with a difficult optimization problem.

Nonetheless, we can exploit the II estimator definition to derive an energy which the minimization will lead to a shape with lower digital elastica value.


\begin{definition}{Unbalance coefficent}
Given digital shape $S \in \Omega$, positive number $r$ and point $p \in \Omega$, the \emph{unbalance coefficient} of $S$ at $p$ is defined as

\begin{align*}
	u(p) = \left( \frac{\pi r^2}{2} - |B_r(p) \cap S| \right)^2.
\end{align*}

\end{definition}

The unbalance coefficient definition is very similar to the II curvature estimator, except by the scaling factor $\frac{3}{R^3}$ and that the unbalance coefficient is defined everywhere and not only on the shape boundary.

The unbalance coefficient is used to estimate the effect of moving the estimation ball center towards the interior or the exterior of the shape. For example, consider the figure \ref{fig:unbalance-plot} in which we plot the unbalance coefficients of points along the diagonal of a square shape. 

\begin{figure}[h!]
\center
\begin{minipage}{0.25\textwidth}
\subfloat{
\includegraphics[scale=1.0]{figures/appendix-potential-elastica/distant-disks-1.png}}\\%
\subfloat{
\includegraphics[scale=1.0]{figures/appendix-potential-elastica/distant-disks-2.png}}\\%
\subfloat{
\includegraphics[scale=1.0]{figures/appendix-potential-elastica/distant-disks-3.png}}
\end{minipage}%
\begin{minipage}{0.75\textwidth}
\includegraphics[scale=0.75]{figures/appendix-potential-elastica/potential-elastica-plot.png}
\end{minipage}
\caption{The unbalance difference of equidistant points from the shape contour preserves squared curvature information.}
\label{fig:unbalance-plot}
\end{figure}


We observe that the unbalance grows if the estimation ball is moved towards the exterior and decreases if the estimation ball is moved towards the interior of the shape. That is an indication that we should remove point $p$ from $S$ to decrease the curvature of the shape at point $p \in \partial S$. 


\section{Formalization}

Let $r>0,k \in \mathbb{R}$. For any point $p \in I(S)$, define

\begin{align*}
	c_{r,k}(p) = k\vec{n}(p).
\end{align*}

To simplify notation, we assume $r,k$ are fixed positive values and we denote $c_j^- = c_{r,-k}(x_j)$ and $c_j^+ = c_{r,k}(x_j)$. We define the energy

\begin{align*}
	E() &= \sum_{x_j}{ x_j (\, u(c_j^+) - u(c_j^-)\, )}
\end{align*}

\begin{definition}{k-potential}
Given digital shape $S$, natural numbers $r>0, k \neq 0$, the \emph{k-potential} at point $p$ is defined as

\begin{align*}
	U_{S,k}(p) &= \sum_{q \in Q(p)}{ u(q),}
\end{align*}

where its zone of influence $Q(p)$ is defined as

\begin{align*}
	\mathcal{Q}(p) &= \left\{\; p \in B_r(q) \; \right\}.
\end{align*}

\end{definition}

\begin{figure}[h!]
\center
\includegraphics[scale=0.5]{figures/appendix-potential-elastica/k-potential.png}
\caption{The blue points forms the interference set of the yellow point.}
\label{fig:unbalance-set}
\end{figure}

The interference set of $p$ is the set of all points $q$ in which $p$ is contained in the estimation ball centered at $q$.   







The k-potential is used to decide which pixels are to be removed or to be kept in the next shape of the flow. 


\begin{definition}{$k$-flow}
	Given digital shape $X$, we define its $k$-flow as
	
	\begin{align*}
		F_k = \Big\{& S^{(i)} \; | \\
			& S^{(0)} = S,\\
		    &S^{(i+1)} = \argmin \sum_{ x_j \in X(I(S^{(i)}))}{ x_j \Delta _j\big(\; U_{S,k}(p) - U_{S,-k}(p) \;\big)} - \phi(S^{(i)},k,x_j) \; \Big\},
	\end{align*}
	
	where $\phi(S^{(i)},k,x_j)$ accounts for pairwise terms that were counted twice.
	
	\begin{align*}
	\phi(S^{(i)},k,x_j) = \frac{x_j}{2}\sum_{ x_l \in X(I(S^{(i)}))}{x_l \Delta _{jl}\big(\; U_{S,k}(p) - U_{S,-k}(p) \;\big)} 
	\end{align*}
     	  
\end{definition}	

In other words, the pixel is labeled zero (one) if its outer (inner) potential is bigger than its inner (outer) potential.

[Results for triangle, square, flower, bean. Non uniform. Balls positioned at radius-2]


We have two issues to tackle. 
\begin{enumerate}
	\item{Why the estimation balls should be centered at distant levels?}
	\item{Why the flow tends to shrink the shape?}
\end{enumerate}


\section{Distant balls}
	The optimization process performs the better when the estimation balls are positioned at distance that maximize the gap between the outer and inner unbalance. Surprisingly, this gap is independent of the curvature value in the boundary. In the experiments, we observe that the highest gap is invariably at $\frac{2}{3}$ of the estimation ball radius.
	
	The reasoning for distance balls is two fold. First, we need at least a $k=1$ in order to compute the unbalance, otherwise it would be zero. The question is how large should be $k$? The energy is easier to optimize if the gap between outer and inner curves is at its maximum. We should find a compromise value for $k$ that assure us a sufficiently large gap. 
	
	Second, the inner and outer balls estimates the impact of shifting the center of the ball from a single point in the boundary. That means that limiting the region of influence of each pair of inner and outer balls is important.
	
	Each pair of inner and outer balls evaluates the shifting of a single point in the boundary.
	
	We do not impose any mapping between the inner and outer balls. It will be too complicated. And we don't need to do it. The mapping is somehow implicitly defined by the distance level curves. 
	
	However, the closer the balls are from the boundary the bigger it is its zone of influence. Ideally, we should set weigths for each pixel in the ball accordingly to its distance from the normal. This is also complicated! 
	
	Nonetheless, there is a natural way to implement that. If the balls are in distant levels, its zone of influence englobes a small area around the normal. We've got the weighting by normals for free!
	
	
	
	

\section{Controlling the shrinking}

\section{Unbalance plot development}
	The unbalance difference at a point $c \in S$ distant $d$ units from the corner is written as
	\begin{align*}
		u_i(c) &= \frac{\pi r^2}{2} - \big( \; a^2 + area( APC ) + area(A'PC) + area(\arc{PQ})  \; \big) \\
		&= \frac{\pi r^2}{2} - \big( \; a^2 + a(P_x-a) + \frac{\theta_P + \theta_Q + \pi/2}{2\pi} \pi r^2\; \big),
	\end{align*}
	
	where
	
	\[
	\begin{array}{ll}
	a = d\sqrt{1/2} & \theta_P = \arctan \frac{a}{P_x-a} \\		
	Q_y = -P_x = a + \sqrt{r^2 -a^2} & \theta_Q = \arctan \frac{a}{|Q_y|-a}		
	\end{array}\]
	
%default = pi*R^2*(abs(t2) + abs(phi))/(2*pi) + a*abs(p2[0])

%g2 = pi*R^2/2 - ( pi*R^2 - ( pi*R^2/4 - default) )	
	
	Similarly, for the outer ball
	\begin{align*}
		u_o(c) &= \frac{\pi r^2}{2} - \big(\; \frac{\pi r^2}{4} - area(APC) - area(AQC) - area(\arc{CP'}) - area(\arc{CQ'}) \; \big)\\
		&= \frac{\pi r^2}{2} - \big( \; \frac{\pi r^2}{4} - aP_x - \frac{\theta_P + \theta_Q}{2\pi}\pi r^2 \; \big),
	\end{align*}
	
	where
	\[
	\begin{array}{ll}
		a = d\sqrt{1/2} & \theta_P = \arctan \frac{a}{P_x+a}\\
		Q_y = -P_x = \sqrt{r^2-a^2} - a & \theta_Q = \arctan \frac{a}{|Q_y|+a}
	\end{array}	 \]
	
\begin{figure}[h!]
	\begin{minipage}{0.5\textwidth}
	\center
	\includegraphics[scale=2.0]{figures/appendix-potential-elastica/balance-dev-1.png}
	\end{minipage}%
	\begin{minipage}{0.5\textwidth}
	\center
	\includegraphics[scale=2.0]{figures/appendix-potential-elastica/balance-dev-2.png}
	\end{minipage}	
\end{figure}
