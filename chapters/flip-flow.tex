\chapter{FlipFlow}
\label{chapter:flip-flow}

In the previous chapter we've presented a local combinatorial model using multigrid convergent estimator that proved to be very sucessfull in optimizing the digital elastica but too slow to be used in practice. We've also attempted to derive a global optimization model, but unfortunately such model is unlikely to be solved in the current state of art of binary optimization techniques. In this chapter we present a second local optimization model that is much faster than algorithm \ref{alg:local-search} but with fewer guarantees of optimality.

\section{Definitions}

Let $S$ be a digital shape with domain $\Omega \subset \mathbb{Z}^2$. We describe a flow $\left \{ S^{(k)} \; | \; k \geq 0, S^{0} = S \right\}$ intended to decrease the digital elastica energy of $S$.

We assume an ordering in $\Omega$, i.e., there exists a bijective function $\omega : \Omega \rightarrow \{1 \cdots |\Omega| \}$. Moreover, let $X_{\omega}:\Omega \rightarrow 2^{\{0,1\}}$ be an operator that transforms digital sets in its corresponding set of binary variables, i.e., given $P \in \Omega$

\begin{align*}
	X_{\omega}(P) := \left\{ x_{\omega(p)} \in \{0,1\} \; | \; p \in P \right\}.
\end{align*}

We'll simply write $X(P)$ if the definition of $\omega$ is clear from the context.

A $\{0,1\}$ assignment of the variables in $X(P)$ is denoted $x(P)$. We define the sum of a set $S$ and an assignment $x(P)$ of $X(P)$ in a domain $\Omega$ as

\begin{align*}
	S + x(P) = S \cup \left\{ p \; | \; p \in P, x_{\omega(p)}=1 \right\}.
\end{align*}

Next, we define the set of optimization variables. In order to guarantee connectivity and thus avoid the enforcement of the topological constraints discussed in \ref{ch6:subsec:topological-constraints}, we limit the optimization region to a subset of $\Omega$, namely the inner pixel boundary of  $S^{(k)}$.

\begin{definition}{Inner pixel boundary}

Given a digital shape $S$ embedded in a domain $\Omega$, we define its inner pixel boundary set $I(S)$ as
\begin{align*}
	I(S) := \left\{ \: p \; | \; p \in S, |\mathcal{N}_4(x) \cap S|<4 \: \right\},
\end{align*}
where $\mathcal{N}_4(p)$ denotes the $4$-adjacent neighbor set of $p$ (without $p$). 
\end{definition}

Further, we write $\overline{I}(S)$ to denote the inner pixel boundary of the complement of $S$, i.e., $\overline{I}(S) := I(\overline{S})$.

The FlipFlow algorithm consists into decide, at each iteration, which pixels in the inner boundary are to be removed from $S^{(k)}$ and which are to be kept in $S^{(k)}$. To simplify notation, the inner pixel boundary of $S^{(k)}$ is simply denoted $I^{(k)}$. At each iteration, the set $X^{(k)}$ of optimization variables is defined as

\begin{align*}
	X^{(k)} := X(I^{(k)}).
\end{align*}

In the case we optimize the complement of $S$, we write $\overline{X}^{(k)}$, i.e., $\overline{X}^{(k)} = X(\overline{I}^{(k)})$.

An assignment of $X^{(k)}$ is simply denoted $x^{(k)}$. We recall the definition of the II digital curvature estimator:

\begin{align}
	\hat{\kappa}^2(p) &= c_1\Big( c_2 - | B_r(p) \cap S^{(k)} | \Big)^2, 
	\label{eq:curvature-estimator-pixels}
\end{align}
where $c_1=3/r^6$ and $c_2=\pi r^2/2$. 

The following sets are important in the expansion of $\eqref{eq:curvature-estimator-pixels}$.


\begin{align*}
	F^{(k)} &:= S^{(k)} \setminus I^{(k)} \\
	F_r^{(k)}(p) &:= F^{(k)} \cap B_r(p)\\
	I_r^{(k)}(p) &:= I^{(k)} \cap B_r(p) \\
	X_r^{(k)}(p) &:= X\big( I_r^{(k)}(p) \big). \\
\end{align*}


Expanding \eqref{eq:curvature-estimator-pixels}, we get 

\begin{align}
  \hat{\kappa}^2(p) &= c_1\Big( c_2 - |F_{r}^{(k)}(p)| - \sum_{x_j \in X_r^{(k)}(p)} {x_j} \Big)^2 \nonumber \\
   &= c_1 \Big( C + 2\left( |F_{r}^{(k)}(p)| - c_2 \right) \hspace{-2mm}\sum_{x_j \in X_{r}^{(k)}(p)}\hspace{-2mm}{x_j} + \hspace{-2mm}\sum_{x_j \in X_{r}^{(k)}(p)}\hspace{-2mm}{x_j^2} + \hspace{-2mm}\sum_{ \substack{x_j,x_l \in X_{r}^{(k)}(p) \\ j<l} }\hspace{-2mm}{2x_jx_l}  \Big),
   \label{eq:digital-squared-curvature-term}
\end{align}
where $C=c_2^2 - 2c_2 \cdot |F_{r}^{(k)}(p)| + |F_{r}^{(k)}(p)|^2$ is a constant. As expression \eqref{eq:digital-squared-curvature-term} is a term to be optimized, we can ignore constants and multiplication factors. Moreover, as we are in a binary optimization setting, we can  further simplify expression \eqref{eq:digital-squared-curvature-term} by exploiting the binary character of variables and eliminating monomials of second order. We define the following family
of energies for given parameters $\Theta=(\alpha,\beta ) \geq 0$
\begin{align}
  E_{(\Theta,m)-flip}(X^{(k)}) =& \sum_{x_j \in X^{(k)}}{\alpha s(x_j)} + \nonumber \\ 
  & \sum_{ \substack{p \in \\ R_m(S^{(k)})}}{ 2c_1 \beta  \Big( { (1/2+ |F_{r}^{(k)}(p)|-c_2) \cdot \sum_{ \substack{ x_j \in \\ X_{r}^{(k)}(p)}}{x_j} } + \sum_{ \substack{j<l, \\ x_j,x_l \in \\ X_{r}^{(k)}(p) } }{x_jx_l} \Big) },
  \label{eq:energy-family}
\end{align}
where $s(\cdot)$ denotes a length penalization term. We recall that $R_m$ refers to the $m-ring$ defined in section \ref{ch6:sec:local-combinatorial-scheme}. Each choice of $m$ generates a different flow, which is generally described in the FlipFlow algorithm \ref{alg:evolution-model}. To optimize energy \eqref{eq:energy-family} we use the QPBOI \ref{} algorithm.


\begin{figure}
\begin{minipage}{0.5\textwidth}
\center
\includegraphics[scale=0.2]{figures/chapter6/contour-information/before-opt.pdf}
\label{fig:contour-info-1}
\end{minipage}%
\begin{minipage}{0.5\textwidth}
\center
\includegraphics[scale=0.2]{figures/chapter6/contour-information/after-opt.pdf}
\label{fig:contour-info-2}
\end{minipage}%
\caption{ Directly using the optimization result of \eqref{eq:energy-family} doesn't decrease squared curvature because contour information is not present in the energy.}
\label{fig:contour-info}
\end{figure}

\begin{algorithm}
 \SetKwData{It}{k}
 \SetKwData{MIt}{maxIt}
 \SetKwData{Delta}{delta}
 \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
 \SetKwComment{comment}{//}{}
 
 \Input{A digital set $S$; The ring number $m$; Length($\alpha$), curvature($\beta$) grouped in parameter vector $\Theta$; the maximum number of iterations \MIt;}
 \BlankLine
 $S^{(0)} \longleftarrow S$\;
 $k \longleftarrow 1$\;
 \While{ \It $<$ \MIt  }{ 	
	\comment{Shrinking mode}
	\If{ \It is even }{	 
	 	$x^{(k-1)} \longleftarrow \displaystyle \argmin_{X^{(k-1)}} E_{(\Theta,m)-flip}(1-X^{(k-1)})$\; 	
 		$S^{(k)} \longleftarrow F^{(k-1)} + x^{(k-1)}$\;
 	}
	\comment{Expansion mode} 	
 	\Else{	
	 	$\overline{x}^{(k-1)} \longleftarrow \displaystyle \argmin_{\overline{X}^{(k-1)}} E_{(\Theta,m)-flip}(1-\overline{X}^{(k-1)})$\;
 		$S^{(k)} \longleftarrow \overline{ \overline{F}^{(k-1)} + \overline{x}^{(k-1)}}$\; 	
 	}
 	
	\It $\longleftarrow$ \It $+1$\;
	
 }
 \caption{FlipFlow algorithm.}
 \label{alg:evolution-model}  
\end{algorithm}

\section{Algorithm discussion}
\label{sec:flipflow-algorithm-discussion}

As discussed in section \ref{ch6:sec:global-optimization}, the topological constraints are a fundamental part in a global optimization model for the digital elastica but the complexity added to it dampens any hope of optimizing it efficiently. In the proposed FlipFlow model, we exclude topological constraints and we end up with the tractable binary second order energy \eqref{eq:energy-family}. However, due the lack of contour information, the minimization of \eqref{eq:energy-family} for $S^{(k)}$ results in undesirable shapes of even higher digital elastica energy values  (see figure \ref{fig:contour-info}). Interestingly, by using the inverse of the optimal assignement, we can derive a shape of lower digital elastica energy. Therefore, the next shape is given by

\begin{align*}
	S^{(k+1)} = S^{(k)} - \argmin _{}{E_{(\Theta,m)-flip}\big(1-X^{(k)}} \big).
\end{align*}

Recall that the integral invariant estimator approaches curvature by computing the difference between half of the area
of a chosen ball and the area of the intersection of this ball with the shape.  In particular, regions of positive
curvature have fewer pixels in their intersection set than on its complement w.r.t the estimation ball. This implies
that variables in such regions are labeled with 1, as the unbalance grows otherwise. We attenuate curvature if we shift
the center of the estimation ball towards the interior of the shape, which means to remove the 1-labeled pixels. That is
why we take the complement of the optimization solution.


The explanation above covers the treatment of convex parts, but the way to treat concavities it's not much different. Indeed, concave regions are convex in the shape complement. The FlipFlow algorithm \ref{alg:evolution-model} is made of two modes: shrinking and expansion. The shrinking mode handles convexities and its reasoning is explained in the last paragraph. The expansion mode operates exactly in the same way, but at the image complement, and by doing this we are able to handle
concavities. It is called expansion mode because the optimization region, in this case, is the outer pixel boundary of
the original shape. Table~\ref{tab:flow-summary} sums up these arguments.

Length and data terms should be properly defined in order to comply with the complement step of the FlipFlow
algorithm. The length penalization is defined as

\begin{align}
  s(x_{w(p)})=\sum_{q \in \mathcal{N}_4(p)}{ t(q) }, \quad \text{where } t(q) = \left\{\begin{array}{ll}
  (x_{w(p)}-x_{w(q)})^2, & \text{if } q \in I^{(k)}\\
  (x_{w(p)}-0), & \text{if } q \in F^{(k)}\\
  (x_{w(p)}-1), & \text{otherwise }
  \end{array}\right.
  \label{eq:length-penalization}
\end{align}
	
\begin{table}
  \center
  \setlength{\extrarowheight}{0.75em}
  \begin{tabular}{|c|c|c|c|} \hline
    shrinking mode &    $\kappa \gg 0$ & $\kappa \geq 0$ &  $\kappa < 0$ \\ \hline
    $x^{(k)}$ & $x_j=1$ & $x_j \in \{0,1\}$ & $x_j=0$ \\ \hline
    $S^{(k+1)} \leftarrow F^{(k)} + x^{(k)}$ & eroded & prob. eroded & unchanged  \\ \hline \hline
    expansion mode &    $\overline{\kappa} \gg 0$ & $\overline{\kappa} \geq 0$ & $\overline{\kappa} < 0$ \\ \hline
    $\overline{x}^{(k)}$ & $\overline{x}_j=1$ & $\overline{x}_j \in \{0,1\}$ & $\overline{x}_j=0$ \\ \hline
    $S^{(k+1)} \leftarrow \overline{\overline{F}^{(k)} + \overline{x}^{(k)}}$ & dilated & prob. dilated & unchanged \\ \hline 
  \end{tabular}
  
  \caption{  Since the curvature is negated when reversing the curve (i.e. $\overline{\kappa}=-\kappa$), this process can only shrink  convex parts in shrink mode and expand concave parts in expansion mode.}
   \label{tab:flow-summary}	  

\end{table}


In figure \ref{fig:m1-square-flow} we show the results of the FlipFlow algorithm for $m=1,\alpha=0, \beta=1$. We observe a global evolution towards rounder shapes, but several artifacts are formed along the boundary. An estimation ball of higher radius evolves the shapes faster, but the contours become noisier. Setting $\alpha >0$ attenuates the problem for lower radius but the produced shapes doesn't match with our intuition of what a flow driven by the squared curvature must be like, as the evaluation of the II estimator can tell us (see figure ). We've identified two reasons for this behavior.

First, we recall that at each iteration, energy \eqref{eq:energy-family} is derived by evaluating the II estimator on a fixed boundary, i.e., the contour information is not included in the optimization problem. Therefore, the flip of a single pixel can turn a previous negative curvature estimation in a positive one (see figure). In our current setting, this is not a desirable property. 

The second reason is related to the properties of the energy and those of the optimization method used. As we discuss in the next chapter, the optimization of energy $E_{(\Theta,1)-flip}$ by QPBO leaves several pixels unlabeled. In section \ref{} we propose a strategy to overcome these issues.



\begin{figure}
\center
\begin{tabular}{p{2.5em}ccc}
& $h=1.0$ & $h=0.5$ & $h=0.25$ \\[2em]
\multirow{2}{*}{$\alpha=0$}& \includegraphics[scale=0.25]{figures/chapter6/radius-effect/triangle/improve/len_pen0/radius-3/summary.pdf} &
\includegraphics[scale=0.24]{figures/chapter6/radius-effect/triangle/improve/len_pen0/radius-5/summary.pdf} &
\includegraphics[scale=0.24]{figures/chapter6/radius-effect/triangle/improve/len_pen0/radius-9/summary.pdf} \\[2em]
& \includegraphics[scale=0.24]{figures/chapter6/radius-effect/flower/improve/len_pen0/radius-3/summary.pdf} &
\includegraphics[scale=0.24]{figures/chapter6/radius-effect/flower/improve/len_pen0/radius-5/summary.pdf} &
\includegraphics[scale=0.24]{figures/chapter6/radius-effect/flower/improve/len_pen0/radius-9/summary.pdf} \\
\hline \\
\multirow{2}{*}{$\alpha=0.5$}& \includegraphics[scale=0.25]{figures/chapter6/radius-effect/triangle/improve/len_pen0.5/radius-3/summary.pdf} &
\includegraphics[scale=0.24]{figures/chapter6/radius-effect/triangle/improve/len_pen0.5/radius-5/summary.pdf} &
\includegraphics[scale=0.24]{figures/chapter6/radius-effect/triangle/improve/len_pen0.5/radius-9/summary.pdf} \\[2em]
& \includegraphics[scale=0.24]{figures/chapter6/radius-effect/flower/improve/len_pen0.5/radius-3/summary.pdf} &
\includegraphics[scale=0.24]{figures/chapter6/radius-effect/flower/improve/len_pen0.5/radius-5/summary.pdf} &
\includegraphics[scale=0.24]{figures/chapter6/radius-effect/flower/improve/len_pen0.5/radius-9/summary.pdf}
\end{tabular}

\caption{The algorithm is very sensitive to the little variations of the estimator, which are particularly important in regions of low squared curvature. Artifacts are somewhat reduced with a length penalization but increases if we use a higher ball radius. For better visualization, curves are displayed every $1/10$ of the number of iterations. }
\label{fig:m1-square-flow}
\end{figure}


\begin{figure}
\center
\subfloat[]{
\includegraphics[scale=0.45]{figures/chapter6/radius-effect/triangle/improve/len_pen0/radius-3/radius-effect.pdf}}%
\subfloat[]{
\includegraphics[scale=0.45]{figures/chapter6/radius-effect/flower/improve/len_pen0/radius-3/radius-effect.pdf}}%
\caption{The digital elastica decreases in a turbulent way.}
\end{figure}


\section{Optimization method}

Let $f$ be a function of $n$ binary variables with unary and pairwise terms, i.e.

\begin{align*}
f(y_1,\cdots, y_n) = \sum_{j}{f_j(y_j)} + \sum_{j < k}{f_{j,k}(y_j,y_k)}.
\end{align*}

The function $f$ is submodular if and only if the following inequality holds for each pairwise term $f_{j,k}$ \cite{kolmogorov04whatenergies}:
\begin{align*}
  \quad f_{j,k}(0,0) + f_{j,k}(1,1) \leq f_{j,k}(0,1) + f_{j,k}(1,0).
\end{align*}

The energy $E_{(\Theta,m)-flip}$ is non-submodular and optimizing it is a difficult problem, which constrains us to use heuristics and
approximation algorithms. The QPBO method \cite{rother07qpbo} transforms the original problem in a max-flow/min-cut
formulation and yields a full optimal labeling for submodular energies. For non-submodular energies the method is
guaranteed to return a partial labeling with the property that the set of labeled variables is part of an optimal
solution. That property is called partial optimality.

In practice, QPBO can leave many pixels unlabeled. There exist two extensions to QPBO that alleviate this limitation:
QPBOI (improve) and QPBOP (probe). The first is an approximation method that is guaranteed to not increase the energy,
but loses the property of partial optimality. The second is an exact method which is reported to label more variables
than QPBO.

The percentage of unlabeled pixels by QPBOP for $E_{(\Theta,m)-flip}$ is quite high, but the percentage decreases to zero as we set $m$
to a value closer to $r$, the estimation ball radius. Therefore, we are more confident in taking the solution for values of $m$ close to $r$. However, the way it
varies across values of $m$ differs from shape to shape, as is illustrated in figure
\ref{fig:unlabeled-versus-iterations}. We also noticed that, for $m=r$, all the pixels were labeled, {which may
  indicate that $E_{(\Theta,r)-flip}$ is an easy instance of the general non-submodular energy $E_{(\Theta,m)-flip}$, but this remains to be
  proved. The number of pairwise terms in $E_{(\Theta,r)-flip}$ is roughly half of those in $E_{(\Theta,1)-flip}$ (see figure
  \ref{fig:ratio-pairwise-terms}), which also explains the higher number of labeled variables.

  We have used QPBOI to solve $E_{(\Theta,m)-flip}$. Naturally, in the case where all pixels are labeled by QPBOP, QPBOI returns the same labeling as QPBOP. In the next section we show that by evaluating the estimation ball at the farthest ring, we preserve a qualitatively measure of curvature, we eliminate the artifacts and we produce smoother flows.


\begin{figure}
\center
\includegraphics[scale=0.5]{figures/chapter6/unlabeled-ratio/plots/pairwise-ratio/h0.25/radius-5/plot-pairwiseratio-lowerHigher-concavities-probe.pdf}
\caption{We plot the ratio of pairwise terms among all $\binom{|X^{(k)}|}{2}$ combinations. The highest ring has roughly half the number of pairwise terms as the lowest ring.}
\label{fig:ratio-pairwise-terms}
\end{figure}


\begin{figure}
\center
\begin{minipage}[b]{0.5\textwidth}
\subfloat[]{ \includegraphics[scale=0.35]{figures/chapter6/unlabeled-ratio/plots/unlabeled-per-iterations/h0.25/radius-3/plot-model-triangle-concavities-probe.pdf}}\\%
\subfloat[]{ \includegraphics[scale=0.35]{figures/chapter6/unlabeled-ratio/plots/unlabeled-per-iterations/h0.25/radius-5/plot-model-triangle-concavities-probe.pdf}}\\%
\subfloat[]{ \includegraphics[scale=0.35]{figures/chapter6/unlabeled-ratio/plots/unlabeled-per-iterations/h0.25/radius-7/plot-model-triangle-concavities-probe.pdf}}%
\end{minipage}%
\begin{minipage}[b]{0.5\textwidth}
\subfloat[]{ \includegraphics[scale=0.35]{figures/chapter6/unlabeled-ratio/plots/unlabeled-per-iterations/h0.25/radius-3/plot-model-flower-concavities-probe.pdf}}\\%
\subfloat[]{ \includegraphics[scale=0.35]{figures/chapter6/unlabeled-ratio/plots/unlabeled-per-iterations/h0.25/radius-5/plot-model-flower-concavities-probe.pdf}}\\%
\subfloat[]{ \includegraphics[scale=0.35]{figures/chapter6/unlabeled-ratio/plots/unlabeled-per-iterations/h0.25/radius-7/plot-model-flower-concavities-probe.pdf}}%
\end{minipage}
\caption{For each plot, we first produce shapes $\left\{ S^{(k)} \right\}$ executing FlipFlow with $m=r$. Then, for each shape in $\left\{ S^{(k)} \right\}$, we execute one iteration of FlipFlow for different values of $m$ and we count the unlabeled pixels. The number of unlabeled pixels by QPBOP remains high for lower values of $m$, and goes to zero when $m=r$. We observe the same behaviour for varying radius values.}
\label{fig:unlabeled-versus-iterations}
\end{figure}



\section{Evaluation across $m$-rings}

In the previous sections we pointed out two reasons for the production of artifacts by the FlipFlow algorithm. One related to the number of unlabeled pixels by the QPBO algorithm and the second due to the small uncertainties of the estimator along regions of low squared curvature. We've seen already that QPBO labels more pixels at outer rings. In this section, we argue that by evaluating the estimation ball along outer
ring sets we can also handle the sensibility issue by focusing the optimization process only on regions with highest squared curvature value.

In figure \ref{} we evaluate several flows for different energies $E_{(\Theta,m)-flip}$. As expected, the number of artifacts decrease as the value of $m$ increases, but the process still tends to shrinking the shape to a single point, resembling the curvature flow. In the next chapter we tackle this issue.

We confirm the stability of the model by looking at the plots of the digital elastica energy values for the produced shapes. Moreover, the produced flow has no difficulties in handling changes on topology, and it presents different speeds for regions with low and high curvature values, as illustrated in figure \ref{fig:mx-speed-variation-hole-filling}.


\begin{figure}
\center
\begin{tabular}{p{3em}ccc}
$m=1$ & \includegraphics[scale=0.25]{figures/chapter6/level-effect/triangle/improve/len_pen0/radius-5/level1/summary.pdf} &
\includegraphics[scale=0.25]{figures/chapter6/level-effect/flower/improve/len_pen0/radius-5/level1/summary.pdf} &
\includegraphics[scale=0.25]{figures/chapter6/level-effect/bean/improve/len_pen0/radius-5/level1/summary.pdf} \\[2em]
$m=3$ & \includegraphics[scale=0.25]{figures/chapter6/level-effect/triangle/improve/len_pen0/radius-5/level3/summary.pdf} &
\includegraphics[scale=0.25]{figures/chapter6/level-effect/flower/improve/len_pen0/radius-5/level3/summary.pdf} &
\includegraphics[scale=0.25]{figures/chapter6/level-effect/bean/improve/len_pen0/radius-5/level3/summary.pdf} \\[2em]
$m=4$ & \includegraphics[scale=0.25]{figures/chapter6/level-effect/triangle/improve/len_pen0/radius-5/level4/summary.pdf} &
\includegraphics[scale=0.25]{figures/chapter6/level-effect/flower/improve/len_pen0/radius-5/level4/summary.pdf} &
\includegraphics[scale=0.25]{figures/chapter6/level-effect/bean/improve/len_pen0/radius-5/level4/summary.pdf} \\[2em]
$m=5$ & \includegraphics[scale=0.25]{figures/chapter6/level-effect/triangle/improve/len_pen0/radius-5/level5/summary.pdf} &
\includegraphics[scale=0.25]{figures/chapter6/level-effect/flower/improve/len_pen0/radius-5/level5/summary.pdf} &
\includegraphics[scale=0.25]{figures/chapter6/level-effect/bean/improve/len_pen0/radius-5/level5/summary.pdf} \\[2em]
\end{tabular}
\caption{By positioning the estimation ball on outer rings, we minimize artifacts creation. The radius of the estimation ball used here equals to $5$ and the curves are displayed every $10$ iterations. \label{fig:mx-square-flow}}
\end{figure}


\begin{figure}
\center
\begin{tabular}{p{3em}ccc}
$m=1$ & \includegraphics[scale=0.25]{figures/chapter6/level-effect/triangle/improve/len_pen0/radius-9/level1/summary.pdf} &
\includegraphics[scale=0.25]{figures/chapter6/level-effect/flower/improve/len_pen0/radius-9/level1/summary.pdf} &
\includegraphics[scale=0.25]{figures/chapter6/level-effect/bean/improve/len_pen0/radius-9/level1/summary.pdf} \\[2em]
$m=5$ & \includegraphics[scale=0.25]{figures/chapter6/level-effect/triangle/improve/len_pen0/radius-9/level5/summary.pdf} &
\includegraphics[scale=0.25]{figures/chapter6/level-effect/flower/improve/len_pen0/radius-9/level5/summary.pdf} &
\includegraphics[scale=0.25]{figures/chapter6/level-effect/bean/improve/len_pen0/radius-9/level5/summary.pdf} \\[2em]
$m=8$ & \includegraphics[scale=0.25]{figures/chapter6/level-effect/triangle/improve/len_pen0/radius-9/level8/summary.pdf} &
\includegraphics[scale=0.25]{figures/chapter6/level-effect/flower/improve/len_pen0/radius-9/level8/summary.pdf} &
\includegraphics[scale=0.25]{figures/chapter6/level-effect/bean/improve/len_pen0/radius-9/level8/summary.pdf} \\[2em]
$m=9$ & \includegraphics[scale=0.25]{figures/chapter6/level-effect/triangle/improve/len_pen0/radius-9/level9/summary.pdf} &
\includegraphics[scale=0.25]{figures/chapter6/level-effect/flower/improve/len_pen0/radius-9/level9/summary.pdf} &
\includegraphics[scale=0.25]{figures/chapter6/level-effect/bean/improve/len_pen0/radius-9/level9/summary.pdf} \\[2em]
\end{tabular}
\caption{By positioning the estimation ball on outer rings, we minimize artifacts creation. The radius of the estimation ball used here equals to $9$ and the curves are displayed every $10$ iterations. \label{fig:mx-square-flow}}
\end{figure}

\begin{figure}
\center
\subfloat[]{
\includegraphics[scale=0.5]{figures/chapter6/level-effect/triangle/improve/len_pen0/radius-5/level1/level-effect.pdf}}%
\subfloat[]{
\includegraphics[scale=0.5]{figures/chapter6/level-effect/triangle/improve/len_pen0/radius-9/level1/level-effect.pdf}}\\[2em]%
\subfloat[]{
\includegraphics[scale=0.5]{figures/chapter6/level-effect/flower/improve/len_pen0/radius-5/level1/level-effect.pdf}}%
\subfloat[]{
\includegraphics[scale=0.5]{figures/chapter6/level-effect/flower/improve/len_pen0/radius-9/level1/level-effect.pdf}}%
\end{figure}

\begin{figure}
\center
\subfloat[]{\includegraphics[scale=0.9]{figures/chapter6/topology-change/summary-wave.pdf}}

\subfloat[]{\includegraphics[scale=0.35]{figures/chapter6/topology-change/summary-square-holes.pdf}}
\caption{The flow evolves regions of high curvature faster, as illustrated in figure (a). Figure (b) illustrates the property of the FlipFlow algorithm to handle changes in topology.}
\end{figure}


\section{Data term and image segmentation}

We present an application of the FlipFlow algorithm to supervised image segmentation. The FlipFlow acts as a contour correction method. Here we use a data fidelity term in order to characterize the object of interest. Given foreground and background seeds selected by the user, we derive mixed Gaussian distributions of color intensities $H_f$,$H_b$, and we define the data fidelity term as the cross-entropy, i.e.
	
\begin{align}
  g(x_{w(p)}) = -x_{w(p)}\log{H_f(p)} - (1-x_{w(p)})\log{H_b(p)}
  \label{eq:data-fidelity}
\end{align}	

We use the FlipFlow algorithm to regularize an initial contour output by some segmentation algorithm or delineated by the user. In this application, the data term of the FlipFlow
is set to the data fidelity term \eqref{eq:data-fidelity}.
	
\begin{algorithm}
 \SetKwData{It}{k}
 \SetKwData{MIt}{maxIt}
 \SetKwData{Tol}{tolerance}
 \SetKwData{Delta}{delta}
 \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
 \SetKwComment{comment}{//}{}
 
 \Input{An image $I$; seeds mask $M$; the estimation ball radius $r$; parameter vector $\Theta=(\alpha, \beta)$; data term weight $(\gamma)$ ; initial dilation $d$; stop condition value \Tol; the maximum number of iterations \MIt;}
 \BlankLine

 $S \longleftarrow$ GrabCut($I,M$)\;
 $S^{(0)} \longleftarrow $ dilate($S$,$d$)\; 
 \Delta $\longleftarrow +\infty$\;
 $k \longleftarrow 0$\;
 \While{ \It $<$ \MIt \bf{and} \Delta $>$ \Tol  }{ 	
 
 	\comment{Shrinking mode}
	\If{ \It is even }{	 
	 	$x^{(k-1)} \longleftarrow \displaystyle \argmin_{X^{(k-1)}} E_{(\Theta,m)-flip}(1-X^{(k-1)}) + \gamma g(X^{(k-1)})$\; 	
 		$S^{(k)} \longleftarrow F^{(k-1)} + x^{(k-1)}$\;
 	}
	\comment{Expansion mode} 	
 	\Else{	
	 	$\overline{x}^{(k-1)} \longleftarrow \displaystyle \argmin_{\overline{X}^{(k-1)}} E_{(\Theta,m)-flip}(1-\overline{X}^{(k-1)}) + \gamma g(\overline{X}^{(k-1)})$\;
 		$S^{(k)} \longleftarrow \overline{ \overline{F}^{(k-1)} + \overline{x}^{(k-1)}}$\; 	
 	}
 

 	\Delta $\longleftarrow |S^{(k)} - S^{(k+1)}|$\;

	\It $\longleftarrow$ \It $+1$\;
	
 }
 \label{alg:contour-correction} 
 \caption{Contour correction algorithm.}
\end{algorithm}	


The algorithm can be initialized by a collection of compact sets, or with the result of a third-party segmentation algorithm, as GrabCut \cite{rother04grabcut}. We include an additional parameter $d$ that dilates the initial sets using a square of side one before executing the flow.

An illustration of the application of the FlipFlow model in image segmentation is presented in figure \ref{fig:ch6-segmentation}. We present a more exhaustive list of experiments and comparisons with other methods in chapter \ref{}.
	
\begin{figure}[ht!]
\center
\begin{tabular}{cccc}
\multirow{2}{*}{Seeds} & \multirow{2}{*}{GrabCut} & $\alpha=0.5, \beta=0.0,$ & $\alpha=0.5, \beta=1.0,$ \\
& & $\gamma=0.5$ & $\gamma=0.5$\\
 	\includegraphics[scale=0.25]{figures/chapter6/segmentation/coala/mt_improve/radius_5/data_0.50/sq_0.00/length_0.50/it_50/seeds.png} & 
 	\includegraphics[scale=0.25]{figures/chapter6/segmentation/coala/mt_improve/radius_5/data_0.50/sq_0.00/length_0.50/it_50/gc-seg.png} & 
 	\includegraphics[scale=0.25]{figures/chapter6/segmentation/coala/mt_improve/radius_5/data_0.50/sq_0.00/length_0.50/it_50/corrected-seg.png} & 
 	\includegraphics[scale=0.25]{figures/chapter6/segmentation/coala/mt_improve/radius_5/data_0.50/sq_1.00/length_0.50/it_50/corrected-seg.png}
\end{tabular}	
\caption{Given foreground (green) and background (gray) seeds at picture (a); GrabCut produces picture (b) which is used as input of the Contour Correction algorithm; in pictures (c) and (d) we display the output of Contour Correction algorithm with and without squared curvature regularization. }
\label{fig:ch6-segmentation}
\end{figure}

\section{Conclusion}

In the next chapter we elucidate the relation between the curvature and the computation of estimation balls at outer rings.

